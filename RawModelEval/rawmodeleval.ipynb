{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sqlparse\n",
    "import difflib\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'synthetic_text_to_sql_train.snappy.parquet', 'test': 'synthetic_text_to_sql_test.snappy.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/gretelai/synthetic_text_to_sql/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =  df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id    domain                                 domain_description  \\\n",
      "0  5097  forestry  Comprehensive data on sustainable forest manag...   \n",
      "\n",
      "  sql_complexity                   sql_complexity_description  \\\n",
      "0    single join  only one join (specify inner, outer, cross)   \n",
      "\n",
      "             sql_task_type                          sql_task_type_description  \\\n",
      "0  analytics and reporting  generating reports, dashboards, and analytical...   \n",
      "\n",
      "                                          sql_prompt  \\\n",
      "0  What is the total volume of timber sold by eac...   \n",
      "\n",
      "                                         sql_context  \\\n",
      "0  CREATE TABLE salesperson (salesperson_id INT, ...   \n",
      "\n",
      "                                                 sql  \\\n",
      "0  SELECT salesperson_id, name, SUM(volume) as to...   \n",
      "\n",
      "                                     sql_explanation  \n",
      "0  Joins timber_sales and salesperson tables, gro...  \n"
     ]
    }
   ],
   "source": [
    "for k in t.iterrows():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_query = f\"\"\"### Instruction:\n",
    "Convert the given natural language question into an accurate SQL query based on the provided database schema.\n",
    "\n",
    "### Input:\n",
    "Question: List all the unique equipment types and their corresponding total maintenance frequency from the equipment_maintenance table.\n",
    "Schema:CREATE TABLE equipment_maintenance (equipment_type VARCHAR(255), maintenance_frequency INT);\n",
    "### Output:\n",
    "SQL Query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT equipment_type, SUM(maintenance_frequency) AS total_maintenance_frequency FROM equipment_maintenance GROUP BY equipment_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": nl_query}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT equipment_type, SUM(maintenance_frequency) AS total_maintenance FROM equipment_maintenance GROUP BY equipment_type;\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_with_ollama(nl_query):\n",
    "    \"\"\"Generates SQL using a locally hosted Ollama model.\"\"\"\n",
    "    response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": nl_query}])\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sql(query):\n",
    "    \"\"\"Formats SQL queries to standard format for comparison.\"\"\"\n",
    "    return sqlparse.format(query, reindent=True, keyword_case=\"upper\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_sql(nl_query):\n",
    "#     \"\"\"Generates SQL using LLaMA model.\"\"\"\n",
    "#     response = generator(nl_query, max_length=128, truncation=True)\n",
    "#     return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(query, conn):\n",
    "    \"\"\"Executes SQL query on SQLite database and returns result.\"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        return cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing sql query: {e}\")\n",
    "        return None  # Return None if query execution fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=45).reset_index(drop=True).head(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluation metrics\n",
    "exact_match_count = 0\n",
    "execution_match_count = 0\n",
    "levenshtein_scores = []\n",
    "total_samples = df.shape[0]  # Adjust based on dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'domain', 'domain_description', 'sql_complexity',\n",
       "       'sql_complexity_description', 'sql_task_type',\n",
       "       'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql',\n",
       "       'sql_explanation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7571801566579635\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():  # Use iterrows() for dictionary-style access\n",
    "    if i >= total_samples:\n",
    "        break\n",
    "\n",
    "    nl_query = row[\"sql_prompt\"]  # FIXED: Changed from text_input → sql_prompt\n",
    "    ground_truth_sql = normalize_sql(row[\"sql\"])  # FIXED: Changed from sql_output → sql\n",
    "\n",
    "    # Generate SQL using LLaMA\n",
    "    generated_sql = normalize_sql(generate_sql_with_ollama(nl_query))\n",
    "\n",
    "    # Exact Match Evaluation\n",
    "    if generated_sql == ground_truth_sql:\n",
    "        exact_match_count += 1\n",
    "\n",
    "    # # Execution Accuracy\n",
    "    # gt_result = execute_sql(ground_truth_sql, conn)\n",
    "    # gen_result = execute_sql(generated_sql, conn)\n",
    "\n",
    "    # if gt_result == gen_result:\n",
    "    #     execution_match_count += 1\n",
    "\n",
    "    # Levenshtein Distance (String Similarity)\n",
    "    lev_score = Levenshtein.normalized_distance(generated_sql, ground_truth_sql)\n",
    "    print(lev_score)\n",
    "    levenshtein_scores.append(lev_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Evaluation Metrics\n",
    "exact_match_acc = (exact_match_count / total_samples) * 100\n",
    "execution_acc = (execution_match_count / total_samples) * 100\n",
    "avg_levenshtein = sum(levenshtein_scores) / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Levenshtein Distance: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Print Results\n",
    "# print(f\"Exact Match Accuracy: {exact_match_acc:.2f}%\")\n",
    "# print(f\"Execution Accuracy: {execution_acc:.2f}%\")\n",
    "print(f\"Average Levenshtein Distance: {avg_levenshtein:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
